---
title: "Actividad Integradora"
author: "Bruno Yánez, Javier Lizárraga, Maximiliano Martínez, Pedro Escoboza"
output:
  pdf_document: default
  html_notebook: default
  html_document:
    df_print: paged
---

```{r}
rm(list=ls());
options(stringAsFactors = FALSE);
```

```{r}
library("gplots"); # heatmap.2()
library("NLP")
library("RISmed");
library("tm");
```

```{r}
# Función para cálculo de diferencia de prueba t student.
t_student_diff <- function(df, index_list_a, index_list_b, col_names =  c("Tumor", "Normal", "Diff")) {
  res <- t(apply(df, 1, 
                 function(x) {
                   m_1 <- mean(x[index_list_a], na.rm = TRUE);
                   m_2 <- mean(x[index_list_b], na.rm = TRUE);
                   m_diff <- abs(m_1 - m_2);
                   c(m_1, m_2, m_diff);
                 }));
  colnames(res) <- col_names;
  return(res);
};

# Función para cálculo de diferencia de prueba t student para dataframes con esquema de clases.
t_student_classes <- function(df, classes, cr_a, cr_b, 
                              col_names = c("A", "B", "p_value", "fold_change")){
  samples_a <- which(classes == cr_a);
  samples_b <- which(classes == cr_b);  
  t_res <- t(apply(df, 1, 
                   function(x){
                     t_test <- t.test(x[samples_a], x[samples_b]);
                     c(t_test$estimate[1], t_test$estimate[2], t_test$p.value, t_test$estimate[1] - t_test$estimate[2]);
                   }));
  colnames(t_res) <- col_names;
  return(t_res);
};

# Regresa un dataframe con los primeros n resultados ordenados por la columna col.
get_top_n <- function(df, col, n, decreasing = FALSE){
  return(head(df[order(col, decreasing=decreasing),],n));
};

# Normalización de datos.
normalize <- function(x, min, max){
  return((x-min)/(max-min));
};

# División de datos en grupos por rangos de valores.
freq_groups <- function(vec, bounds){
  num_bounds <- length(bounds);
  freqs <- integer(num_bounds);
  for (i in 2:num_bounds){
    for (j in 1:length(vec)){
      if (vec[j] >= bounds[i-1] & vec[j] < bounds[i]){
        freqs[i] = freqs[i] + 1;
      }
    }
  }
  return(freqs);
};

```

## Análisis de Multi_Cancer_Data

```{r}
load("Multi_Cancer_Data.Rdata");
df <- multi_cancer_data;
rm(multi_cancer_data);
```

### Diferenia entre muestras normales y muestras de cáncer color

```{r}
# Selección de muestras normales.
normal_samples_indexes <- grep("Normal", colnames(df));
print(normal_samples_indexes);

# Selección de muestras de cáncer colorrectal.
colorectal_cancer_indexes <- grep("Tumor__Colorectal", colnames(df));
print(colorectal_cancer_indexes);

# Prueba t student.
tstudent_normal_with_colorectal <- data.frame(t_student_diff(df, normal_samples_indexes, colorectal_cancer_indexes,));

# Seleccionar 10 entradas con mayor diferencia.
tstudent_normal_with_colorectal <- get_top_n(tstudent_normal_with_colorectal, tstudent_normal_with_colorectal$Diff, 10, decreasing=TRUE);

print(tstudent_normal_with_colorectal);
```

## Análisis de TCGA_COADREAD_comp_data

```{r}
rm(list=setdiff(ls(), lsf.str()));
load("TCGA_COADREAD_comp_data.RData");
df <- tcga_coadread;
rm(tcga_coadread);
```

### Diferencia entre jóvenes y adultos

```{r}
# Prueba de t student para TCGA COARDREAD por las clases Young  y Old.
tcga_t_test <- t_student_classes(df,tcga_coadread_class,"Young","Old",c("Young", "Old", "p_value", "Fold-Change"));

# Filtración de datos para eliminar entradas no significativas.
tcga_t_test_filter <- apply(tcga_t_test[,1:2],1,function(x){all(x<1)});
tcga_t_test <- tcga_t_test[-which(tcga_t_test_filter),];

# Ordenar por diferencia.
tcga_t_test <- tcga_t_test[order(tcga_t_test[,4], decreasing=TRUE),];

# Genes con mayor diferencia de expresión entre jóvenes y ancianos.
print("# Genes con mayor diferencia de expresión entre jóvenes y ancianos:");
write.table(rownames(tcga_t_test[which(tcga_t_test[,4] > 0),])[1:20], sep='\t', quote=F, row.names=F, col.names=F);
```
```{r}
# Generar matriz para mapa de calor.
hm_mat <- tcga_t_test[rownames(tcga_t_test)[1:20],];

# Remover columnas de p_value y fold_change.
hm_mat <- hm_mat[,-(3:4),drop=FALSE];
colnames(hm_mat) <- colnames(tcga_t_test)[1:2];

# Normalizar valores de expresión.
exp_values <- c(hm_mat[,1], hm_mat[,2]);
min_exp_values <- min(exp_values);
max_exp_values <- max(exp_values);

hm_mat[,1] <- normalize(hm_mat[,1], min_exp_values, max_exp_values);
hm_mat[,2] <- normalize(hm_mat[,2], min_exp_values, max_exp_values);


num_colors = 128;
```

### Mapa de calor

```{r}
# Construcción de mapa de calor.
colors_h <- colorRampPalette(c("darkblue","red"))(num_colors);
h_breaks <- seq(from=0, to=1, length=num_colors+1);

heatmap.2(hm_mat, col=colors_h, trace="none", breaks=h_breaks, cexCol=1);
```

## Análisis de 9_PACIENTES_DE_NUEVO_INGRESO.csv

```{r}
rm(list=setdiff(ls(), lsf.str()));
df <- read.csv("9_PACIENTES_DE_NUEVO_INGRESO.csv");

# Selección de entradas de tumores de colon.
colon_cancer <- df[grep("COLON", df$DESCRIPCION.DIAGNOSTICO),];
print(head(colon_cancer));

# Cáncer de colon por edad.
ranges <- c(0,10,20,30,40,50,60,70,80,90,100);
age_freq <- freq_groups(colon_cancer$EDAD, ranges);
label <- c("[0 10)", "[10 20)","[20 30)","[30 40)","[40 50)","[50 60)", "[60 70)", "[70 80)","[80 90)","[90 100)", "[100 110)");
barplot(age_freq,  main="Cáncer de colon por edad", xlab="Edad", names.arg=label, cex.names=0.5);

# Cáncer de colon por estado.
state_freq <- as.data.frame(table(colon_cancer$ESTADO));
state_freq <- state_freq[which(state_freq$Freq != 0),];
state_freq <- state_freq[order(state_freq$Freq, decreasing=TRUE),];
barplot(state_freq$Freq, main="Cáncer de colon por estado", xlab="Estado", names.arg=state_freq$Var1, cex.names=0.5,las=2 );
```

## Búsqueda de artículos relacionados en PubMed

```{r}

# Correr la opción paraque no se lean los strings como factores.
options(stringsAsFactors = F)

# Creamos un query para buscar artículos en PUBMED desde R. Usando los operadores
# lógicos AND y OR y la opción TitleAbstract.

query_colon <- "\"colon\"[TIAB] AND \"cancer\"[TIAB] AND \"young\"[TIAB] AND
(\"mutation\"[TIAB] OR \"alteration\"[TIAB] OR \"treatment\"[TIAB] OR
\"hereditary\"[TIAB])"
#usamos la opción EUtilsSummary de RISmed

search_query <- EUtilsSummary(query_colon)
summary(search_query)

#Después, obtenemos un data frame con el título, abstract y ID de los artículos.
records <- EUtilsGet(search_query)
pubmed_data <- data.frame('Title' = ArticleTitle(records), 'Abstract' =
AbstractText(records), 'PID' = ArticleId(records))
pubmed_data [1:3,c("Title","PID")]

#Quitamos caracteres (. : , ; [ ]) del título y el abstract.
pubmed_data$Title <- gsub(pattern = "//.|:|,|;|//[|//]", replacement = "",
pubmed_data$Title)
pubmed_data$Abstract <- gsub(pattern = "//.|:|,|;|//[|//]", replacement = "",
pubmed_data$Abstract)

#Convertimos todo a minúsculas
pubmed_data$Title <- tolower(pubmed_data$Title)
pubmed_data$Abstract <- tolower(pubmed_data$Abstract)
pubmed_data$Title[1:3]

#usamos la función strsplit y unlist para obtener las palabras contenidas en el abstract.
unlist(strsplit(pubmed_data$Abstract[1], " "))[1:10]

#Hay algunos artículos que pudieran no incluir el abstract
which(pubmed_data$Abstract == "")

#Creamos el vector sobre el cuál vamos a iterar:
word_list <- c()

#El bucle para todos los abstracts
for (i in 1:length(pubmed_data$Abstract)){
  #Obtenemos las palabras como vector
  aux_word <- unlist(strsplit(pubmed_data$Abstract[i], " "))
  
  #eliminamos abstracts vacíos con la condicionante "if"
  if (length(aux_word) > 0){
    #Concatenamos las palabras y el ID. Con c bind recuperamos en una columna los IDs en
    # donde se encuentran las palabras y los concatenamos con la columna aux_word.
    aux_list <- cbind(pubmed_data$PID[i], aux_word)
    #Pegamos este data frame en el vector inicial con row bind.
    word_list <- rbind(word_list, aux_list)
  
}

}

colnames(word_list) <- c("PID","Word")
ncol(word_list)
nrow(word_list)
dim(word_list)
word_list[1:5,]
head(word_list)

#Usamos la libreria tm para obtener la lista de "stopwords(palabras vacías)" (articulos,
#adverbios, pronombres, conjunciones)
library(tm)
stop_words <- stopwords(kind = "en")
stop_words

#guardamos los índices de las palabras de nuestra lista que corresponden a stopwords y
#que deben ser removidas
index_stop_word <- which(word_list[,2] %in% stop_words)
length(index_stop_word)
dim(word_list)
word_list <- word_list[-index_stop_word,]
dim(word_list)
head(word_list)

#Ahora podemos ver el top10 de las palabras mas frecuentes
sort(table(word_list[,2]), decreasing = T) [1:10]

word_df <- data.frame(PID=as.numeric(word_list[,1]), Word=word_list[,2],
PIDWord=as.character(apply(word_list, 1, paste, collapse="_")))
word_df[1:5,]
dup_index <- duplicated(word_df$PIDWord)
word_df$PIDWord[1:30]
length(which(dup_index))
dim(word_df)
word_df <- word_df[-which(dup_index),]
dim(word_df)

#volvemos a ver el top de las palabras mas frecuentes
sort(table(word_df[,2]), decreasing = T) [1:5]

#ordenamos el data frame por ID en orden decreciente para tener los artículos más
#recientes
word_df <- word_df[order(word_df$PID, decreasing=T),]
print(word_df[1:40,]);

```
